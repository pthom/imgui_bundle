# Bundle ML notebook


## Real-Time ML Training with Interactive GUI in Jupyter

[00:00:00]

Hey everyone! Today I'm showing you something really cool - training a neural network in a Jupyter notebook with a live, interactive GUI that lets you tune hyperparameters in real-time.

Disclaimer: this video uses an artificial voice.

We will use Dear ImGui Bundle, which brings immediate-mode GUI capabilities to Python. Let's dive in!

We're training a simple neural network on the Iris dataset using PyTorch. Nothing fancy - just 3 layers, classifying flower species.

Here I'm setting up the data, defining the model, and creating a shared training state that both our GUI and training loop can access.

The key is this training\_state dictionary - it holds our hyperparameters, training metrics, and control flags.

Now here's where it gets interesting.

We can easily define a GUI in order to enable the user to tune hyperparameters. Here, we add a slider to adjust the learning rate. And here we plot the loss and accuracy.

To [00:01:00] run this GUI, I call immapp.nb.start() - this launches the GUI in non-blocking mode.

See? The cell completes immediately, but the GUI window stays open on top of the browser. This is crucial - we can now run other cells while the GUI is active.

The GUI shows our training metrics, hyperparameter controls, and live plots. But right now, nothing's training yet.

Let's start the training loop. This is an async function that runs alongside the GUI.

Watch the loss curve - it's updating in real-time! We can see the training and test accuracy climbing.

The magic happens here: await async\_io.sleep(0) - this yields control after each epoch, letting the GUI update smoothly. Both the training loop and GUI are cooperating through async\_io.

Now the fun part - let's interact with it while it's training!

I can pause training, make adjustments...and resume. This is incredibly useful for experimenting with hyperparameters without [00:02:00] restarting training from scratch.

I'm adjusting the learning rate - watch how the loss curve immediately responds. Higher learning rate, faster but noisier convergence.

Let me reset the training and try different settings. Starting fresh with a lower learning rate - see how the curve is smoother but converges more slowly?

This pattern could work for any ML training.

Once the training is finished, we may run the GUI one last time in blocking mode, in order to capture a screenshot which will be displayed and saved inside the notebook.

All the code is in the video description - it's part of the Dear ImGUI Bundle documentation. If you want to add interactive GUIs to your ML workflows, give it a try! Thanks for watching, and see you in the next one!

